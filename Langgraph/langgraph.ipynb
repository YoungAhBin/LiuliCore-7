{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1b1914-3c2a-4156-a913-cccd81eaaf71",
   "metadata": {},
   "source": [
    "# 单智能体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaf9822-248d-4097-94fc-d422c0a3ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# models\n",
    "# pip install langchain_openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "chatLLM = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    model=\"qwen-plus\",  # 此处以qwen-plus为例，您可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03436cb4-8e96-479f-b03c-9839d28109a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# agents\n",
    "# pip install -U langgraph   /  pip install -U langchain\n",
    "# 包括记忆、工具、结构化输出\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# 记忆\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# 结构化输出\n",
    "class WeatherResponse(BaseModel):\n",
    "    conditions: str\n",
    "\n",
    "# 工具\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=chatLLM,\n",
    "    tools=[get_weather],\n",
    "    checkpointer=checkpointer,\n",
    "    response_format=WeatherResponse,\n",
    "    system_prompt=\"You are a helpful assistant. Be concise and accurate.\"\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "# 传入同样的config，就能获得该config下的全部对话\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "sf_response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n",
    "    config  \n",
    ")\n",
    "ny_response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what about new york?\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "# 获取结构化回复\n",
    "ny_response[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808377c-4a69-42b7-a0ed-13735ccf26fb",
   "metadata": {},
   "source": [
    "# 多智能体"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df50ba7-b53b-47a5-8468-4c47d4606b21",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0947ee55-935a-4bed-8fe1-ffb962609e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义状态机\n",
    "# 状态机通过状态的传递把所有节点chuan'lian\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4701ccff-a78a-4bae-918e-5fa6808aa71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义模型节点\n",
    "\n",
    "# models\n",
    "# pip install langchain_openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "chatLLM = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    model=\"qwen-plus\",  # 此处以qwen-plus为例，您可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [chatLLM.invoke(state[\"messages\"])]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ce370-558a-41e6-a4f6-5cf4d0f2d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 状态机增加节点\n",
    "# 参数是：节点名、节点函数\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c0e38-1a47-44cc-abd0-f0fb79f9178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义开始节点\n",
    "\n",
    "graph_builder.add_edge(START, \"chatbot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2d5555-e811-4e9a-82c1-7412020fa2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义结束节点\n",
    "\n",
    "graph_builder.add_edge(\"chatbot\", END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32123af4-8aea-41b2-8c44-f29cd5ce73e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 编译图\n",
    "\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa18c87-9067-49d7-832e-ed5e4a5a2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 可视化图\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7750e2d7-3546-46ce-8e04-a91a457dfe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 运行状态机\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1eb7cf-ff0d-4118-958e-d6a7d48a88cf",
   "metadata": {},
   "source": [
    "## 模型 + 工具·自定义工具类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e31285-3509-491a-8b51-2d28f3b23958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 搜索工具\n",
    "# pip install -U langchain-tavily\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"现在背景时间是那一年几月几日星期几？\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b118257-97b9-4219-91ed-9b46539c0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义模型\n",
    "\n",
    "# models\n",
    "# pip install langchain_openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "chatLLM = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    model=\"qwen-plus\",  # 此处以qwen-plus为例，您可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb69f3d-efd9-4858-882b-e0888a97f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义状态机、定义带搜索工具的聊天机器人节点\n",
    "# llm绑定工具，只能让llm知道这个工具，产生对这个工具的调用信息\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = chatLLM.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb48f4d-cf79-43e3-ae35-288326d35ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义工具节点\n",
    "# 定义的这个类是根据llm产生的工具调用信息，调用工具，产生ToolMessage\n",
    "\n",
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc192ee8-07b9-44f1-a5c1-ce58d641778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义边、渲染图\n",
    "\n",
    "def route_tools(\n",
    "    state: State,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538e055-cd94-4ef7-b5c5-e98c06d4f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 可视化图\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e0eb1-b450-4cd7-b6bc-3fc424babfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 交互\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d2eb33-3e02-4f0d-b335-bcc70211b75a",
   "metadata": {},
   "source": [
    "## 模型 + 工具·官方工具类导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b2406-aaf0-4c41-aceb-4c094ae549ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义模型\n",
    "\n",
    "# models\n",
    "# pip install langchain_openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "chatLLM = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    model=\"qwen-plus\",  # 此处以qwen-plus为例，您可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af5daea-5e12-4a9c-9d2d-4cbf6d65695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义工具·langchain的工具定义规范\n",
    "\n",
    "from pydantic import BaseModel, Field  # Import Pydantic for data validation\n",
    "from langchain.tools import tool  # Import the tool decorator from LangChain\n",
    "from typing import Literal  # Import Literal for type hinting with specific values\n",
    "\n",
    "class PhoneNumberLookupInput(BaseModel):\n",
    "    \"\"\"Input for phone number lookup queries.\"\"\"\n",
    "    name: str = Field(description=\"Name of the person or business to look up\")\n",
    "    location: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"City, state, or country to narrow down the search\"\n",
    "    )\n",
    "    type: Literal[\"personal\", \"business\", \"government\"] = Field(\n",
    "        default=\"personal\",\n",
    "        description=\"Type of phone number to search for\"\n",
    "    )\n",
    "    include_address: bool = Field(\n",
    "        default=False,\n",
    "        description=\"Whether to include address information in results\"\n",
    "    )\n",
    "\n",
    "\n",
    "@tool(\"phone_lookup\", description=\"Looks up phone numbers for people or businesses. Use this when you need contact information.\", args_schema=PhoneNumberLookupInput)\n",
    "def lookup_phone_number(name: str, location: str = \"\", type: str = \"personal\", include_address: bool = False) -> str:\n",
    "    \"\"\"Find phone numbers based on name and optional filters.\"\"\"\n",
    "    # This would contain actual implementation to search a database\n",
    "    # For demonstration purposes, returning a placeholder\n",
    "    return f\"Found phone number for {name} in {location if location else 'all locations'}: 555-123-4567\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57668f2b-7511-4972-88db-9d711be631d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 建立图\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 使用Tavily，如果没有显式的注入api key，它会自动从系统环境中读取\n",
    "# tool = TavilySearch(max_results=2)\n",
    "tools = [lookup_phone_number]\n",
    "llm_with_tools = chatLLM.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[lookup_phone_number])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c42f3-cc46-4bb8-9e8d-461c0ff56738",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 交互\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7552df3f-9cbc-4062-8396-63ee7d8d6bd7",
   "metadata": {},
   "source": [
    "## 模型 + 工具 + 记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c862fcaa-5902-4447-a132-f1ec22be2046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义模型\n",
    "\n",
    "# models\n",
    "# pip install langchain_openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "chatLLM = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    model=\"qwen-plus\",  # 此处以qwen-plus为例，您可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067ef63-e58d-4a12-b536-d6db9de082f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义工具·langchain的工具定义规范\n",
    "\n",
    "from pydantic import BaseModel, Field  # Import Pydantic for data validation\n",
    "from langchain.tools import tool  # Import the tool decorator from LangChain\n",
    "from typing import Literal  # Import Literal for type hinting with specific values\n",
    "\n",
    "class PhoneNumberLookupInput(BaseModel):\n",
    "    \"\"\"Input for phone number lookup queries.\"\"\"\n",
    "    name: str = Field(description=\"Name of the person or business to look up\")\n",
    "    location: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"City, state, or country to narrow down the search\"\n",
    "    )\n",
    "    type: Literal[\"personal\", \"business\", \"government\"] = Field(\n",
    "        default=\"personal\",\n",
    "        description=\"Type of phone number to search for\"\n",
    "    )\n",
    "    include_address: bool = Field(\n",
    "        default=False,\n",
    "        description=\"Whether to include address information in results\"\n",
    "    )\n",
    "\n",
    "\n",
    "@tool(\"phone_lookup\", description=\"Looks up phone numbers for people or businesses. Use this when you need contact information.\", args_schema=PhoneNumberLookupInput)\n",
    "def lookup_phone_number(name: str, location: str = \"\", type: str = \"personal\", include_address: bool = False) -> str:\n",
    "    \"\"\"Find phone numbers based on name and optional filters.\"\"\"\n",
    "    # This would contain actual implementation to search a database\n",
    "    # For demonstration purposes, returning a placeholder\n",
    "    return f\"Found phone number for {name} in {location if location else 'all locations'}: 555-123-4567\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c85de-699b-45db-9216-1c7076fc2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 建立图\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 使用Tavily，如果没有显式的注入api key，它会自动从系统环境中读取\n",
    "# tool = TavilySearch(max_results=2)\n",
    "tools = [lookup_phone_number]\n",
    "llm_with_tools = chatLLM.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[lookup_phone_number])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99087f8f-6244-4678-93a3-dd78151e9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建内存记忆检查点\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "memory = InMemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f747b3b0-0dfc-4af6-bcbb-7821a9ff0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建对话线程\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e8405d-1228-4240-83ea-0cc4f4dc8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 首次交互\n",
    "\n",
    "user_input = \"Hi there! My name is Will.\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f956f7af-6743-4484-a730-c5501c33d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 再次交互，测试记忆\n",
    "\n",
    "user_input = \"Remember my name?\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1796b99-0141-42a9-8550-4786ae254a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "snapshot = graph.get_state(config)\n",
    "snapshot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d0b7c-212a-4107-8491-a454d1fcfa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 获取下一个执行的节点\n",
    "\n",
    "snapshot.next \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b24d6f-a0cc-41c3-98c6-87763b554753",
   "metadata": {},
   "source": [
    "## 人机交互控制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf32ce0-1b23-4fea-bcbe-4850e45f5818",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 定义模型\n",
    "\n",
    "# models\n",
    "# pip install langchain_openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "chatLLM = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    model=\"qwen-plus\",  # 此处以qwen-plus为例，您可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a096a9-3d51-44a0-bf44-30c934cad50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 建立图（包含人工打断工具）\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "@tool\n",
    "def human_assistance(query: str) -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt({\"query\": query})\n",
    "    return human_response[\"data\"]\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "llm_with_tools = chatLLM.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # Because we will be interrupting during tool execution,\n",
    "    # we disable parallel tool calling to avoid repeating any\n",
    "    # tool invocations when we resume.\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbda2bb-eb8d-4a57-a60d-1ba292bafb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 建立记忆检查点\n",
    "\n",
    "memory = InMemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1845182a-96d7-467e-9b60-376bf273095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 可视化图\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af99469d-b894-424b-8e93-8b39b3356ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 交互\n",
    "\n",
    "user_input = \"我需要一些关于构建人工智能代理的专家指导。你能帮我请求协助吗？\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b5760-c5b8-4b37-a118-42e1d7c98ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 获取下一个将被执行的节点\n",
    "\n",
    "snapshot = graph.get_state(config)\n",
    "snapshot.next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14955abe-11b4-47b5-ad7c-20e28ca5c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 打断后，输入人类反馈，让human_assistance函数执行完\n",
    "\n",
    "human_response = (\n",
    "    \"我们，这些专家在这里为您提供帮助！我们建议您查看 LangGraph 来构建您的智能代理。\"\n",
    "    \"它比简单的自主代理更加可靠且可扩展。\"\n",
    ")\n",
    "\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f43b01e-2726-458b-a477-9c7fcc03391e",
   "metadata": {},
   "source": [
    "## 更改状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3343dc4-c758-499a-86d2-d19dcedef7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义模型\n",
    "\n",
    "# models\n",
    "# pip install langchain_openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "chatLLM = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    model=\"qwen-plus\",  # 此处以qwen-plus为例，您可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b759f7-e16b-4934-af35-c95ab246368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义状态\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b054d46b-dba5-47b0-9369-2c389d06c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义工具\n",
    "# 这个人工干预里面，先打断流程，然后获取人类回复，再然后根据人类回复判断是否做出改变对state里面的三个值重新进行定义，最后更新state\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "@tool\n",
    "# Note that because we are generating a ToolMessage for a state update, we\n",
    "# generally require the ID of the corresponding tool call. We can use\n",
    "# LangChain's InjectedToolCallId to signal that this argument should not\n",
    "# be revealed to the model in the tool's schema.\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "    # If the information is correct, update the state as-is.\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    # Otherwise, receive information from the human reviewer.\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    # This time we explicitly update the state with a ToolMessage inside\n",
    "    # the tool.\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    # We return a Command object in the tool to update our state.\n",
    "    return Command(update=state_update)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2c8171-d87d-47b7-bda0-c7608a5db8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义图\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "llm_with_tools = chatLLM.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    assert(len(message.tool_calls) <= 1)\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = InMemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d596cc43-2e1e-49fb-a5d0-4f4cff57f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 交互\n",
    "\n",
    "user_input = (\n",
    "    \"你能查一下LangGraph是什么时候发布的吗？\"\n",
    "    \"当你有答案时，使用 human_assistance 工具进行审核。\"\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c39af-659f-4f48-9f10-0d72ea36e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 打断后，输入人类反馈，让human_assistance函数执行完\n",
    "\n",
    "human_command = Command(\n",
    "    resume={\n",
    "        \"name\": \"LangGraph\",\n",
    "        \"birthday\": \"Jan 17, 2024\",\n",
    "    },\n",
    ")\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa6743-501c-4c44-bbc7-62fc6b488930",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 查询更改情况\n",
    "\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f23c02-2027-455b-a0a4-cecb5303e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 手动更新状态\n",
    "# 可以以这种方式更新state中的任何一个键的值\n",
    "\n",
    "graph.update_state(config, {\"name\": \"LangGraph (library)\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f7201-9d75-4810-9ea2-e276b10b58f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 查询更改情况\n",
    "\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa7b482-a2a8-42c0-a4e8-58d37e6d76d1",
   "metadata": {},
   "source": [
    "## 时间旅行（重新生成回答）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a934ade-ca12-4d1a-ad40-49c2cfe22432",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义模型\n",
    "\n",
    "# models\n",
    "# pip install langchain_openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "chatLLM = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    model=\"qwen-plus\",  # 此处以qwen-plus为例，您可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a52833a-5ab7-4124-94e4-9334fa73cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义图\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "llm_with_tools = chatLLM.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = InMemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ddf6b8-89df-4713-8828-e924baa9a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 交互1\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"我正在学习 LangGraph。\"\n",
    "                    \"你能帮我对此做一些调查吗？\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5abaa3-771d-47a5-b2dc-45413f0f49d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 交互2\n",
    "\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"是的，那很有帮助。也许我会用它构建一个自主代理！\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d46f38-4524-4a54-aee5-536bb9fa21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 打印全部流程节点\n",
    "\n",
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 6:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc5fd95-2b20-41cf-a823-664fc8611a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 检查点会在图的每一步保存，这样可以通过调用提取任何一步\n",
    "\n",
    "print(to_replay.next)\n",
    "print(to_replay.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01698b1c-14cd-4217-b7c6-359b629c58f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "# to_replay.config会提供'checkpoint_id': '1f0aefae-4f7d-65e4-8006-41f74551bf4b'，大模型就知道从这个检查点开始添加状态\n",
    "\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7e6fbd-7f50-406a-aa48-03e9420769d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
