{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e56bb1-43d5-4899-9c7e-e26eab1a7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 设置环境变量WANDB_MODE为disabled，禁止在微调模型的适合连接wandb记录微调过程，因为会发生SSL错误\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6afaaba6-1c25-4d76-a3de-9f80c5e77309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " See https://github.com/google-research/timesfm/blob/master/README.md for updated APIs.\n",
      "Loaded PyTorch TimesFM, likely because python version is 3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)].\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 配置模型，下载到本地的文件作为模块导入需要指明可用于搜索模块的文件夹sys.path.append\n",
    "# 为了避免下载模型连接不到网页的SSL错误，提前下载模型，传入路径代替下载模型\n",
    "# TimesFm类本身就有path参数，传入了就不用下载了\n",
    "\n",
    "from os import path\n",
    "import torch\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\传防科电脑\\Desktop\\timesfm-master\\src\")\n",
    "from timesfm import TimesFm, TimesFmCheckpoint, TimesFmHparams\n",
    "from timesfm.pytorch_patched_decoder import PatchedTimeSeriesDecoder\n",
    "from finetuning.finetuning_torch import FinetuningConfig, TimesFMFinetuner\n",
    "\n",
    "def get_model(load_weights: bool = False):\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  repo_id = \"google/timesfm-2.0-500m-pytorch\"\n",
    "  hparams = TimesFmHparams(\n",
    "      backend=device,\n",
    "      per_core_batch_size=32,\n",
    "      horizon_len=128,\n",
    "      num_layers=50,\n",
    "      use_positional_embedding=False,\n",
    "      context_len=192,  # Context length can be anything up to 2048 in multiples of 32\n",
    "  )\n",
    "  tfm = TimesFm(hparams=hparams, checkpoint=TimesFmCheckpoint(huggingface_repo_id=repo_id, path=r\"C:\\Users\\传防科电脑\\Desktop\\timesfm\\timesfm_model\\torch_model.ckpt\"))\n",
    "\n",
    "  model = PatchedTimeSeriesDecoder(tfm._model_config)\n",
    "  if load_weights:\n",
    "    # checkpoint_path = path.join(snapshot_download(repo_id), \"torch_model.ckpt\")\n",
    "    loaded_checkpoint = torch.load(r\"C:\\Users\\传防科电脑\\Desktop\\timesfm\\timesfm_model\\torch_model.ckpt\", weights_only=True)\n",
    "    model.load_state_dict(loaded_checkpoint)\n",
    "  return model, hparams, tfm._model_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c61a503-82a1-44d1-8aaf-390ce0943fd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model, hparams, tfm_config = get_model(load_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "276e2a4a-9379-43ef-96fe-630c4d4c1c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchedTimeSeriesDecoder(\n",
       "  (input_ff_layer): ResidualBlock(\n",
       "    (hidden_layer): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=1280, bias=True)\n",
       "      (1): SiLU()\n",
       "    )\n",
       "    (output_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (residual_layer): Linear(in_features=64, out_features=1280, bias=True)\n",
       "  )\n",
       "  (freq_emb): Embedding(3, 1280)\n",
       "  (horizon_ff_layer): ResidualBlock(\n",
       "    (hidden_layer): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (1): SiLU()\n",
       "    )\n",
       "    (output_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (residual_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "  )\n",
       "  (stacked_transformer): StackedDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-49): 50 x TimesFMDecoderLayer(\n",
       "        (self_attn): TimesFMAttention(\n",
       "          (qkv_proj): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "          (o_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (mlp): TransformerMLP(\n",
       "          (gate_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (down_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (input_layernorm): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605fd839-1dab-4d4f-9773-b9f85f5e8447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimesFmHparams(context_len=192, horizon_len=128, input_patch_len=32, output_patch_len=128, num_layers=50, num_heads=16, model_dims=1280, per_core_batch_size=32, backend='cpu', quantiles=(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9), use_positional_embedding=False, point_forecast_mode='median')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ea7d0f-0786-4c4f-b0d1-a8b26818286a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimesFMConfig(num_layers=50, num_heads=16, num_kv_heads=16, hidden_size=1280, intermediate_size=1280, head_dim=80, rms_norm_eps=1e-06, patch_len=32, horizon_len=128, quantiles=(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9), pad_val=1123581321.0, tolerance=1e-06, dtype='bfloat32', use_positional_embedding=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56de03bb-b084-4bc8-8921-f2c7a6c7b955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinetuningConfig(batch_size=256, num_epochs=5, learning_rate=0.0001, weight_decay=0.01, freq_type=1, use_quantile_loss=True, quantiles=None, device='cpu', distributed=False, gpu_ids=[0], master_port='12358', master_addr='localhost', use_wandb=True, wandb_project='timesfm-finetuning', log_every_n_steps=10, val_check_interval=0.5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 配置模型为题哦的config\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\传防科电脑\\Desktop\\timesfm-master\\src\")\n",
    "from finetuning.finetuning_torch import FinetuningConfig, TimesFMFinetuner\n",
    "\n",
    "config = FinetuningConfig(batch_size=256,\n",
    "                        num_epochs=5,\n",
    "                        learning_rate=1e-4,\n",
    "                        use_wandb=True,\n",
    "                        freq_type=1,\n",
    "                        log_every_n_steps=10,\n",
    "                        val_check_interval=0.5,\n",
    "                        use_quantile_loss=True)\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f59971-f646-4f72-91cd-0a391039ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 微调数据的预处理\n",
    "# 数据不够，修改prepare_datasets函数的train_split，可增加训练、验证数据的样本数\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "  \"\"\"Dataset for time series data compatible with TimesFM.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               series: np.ndarray,\n",
    "               context_length: int,\n",
    "               horizon_length: int,\n",
    "               freq_type: int = 0):\n",
    "    \"\"\"\n",
    "        Initialize dataset.\n",
    "\n",
    "        Args:\n",
    "            series: Time series data\n",
    "            context_length: Number of past timesteps to use as input\n",
    "            horizon_length: Number of future timesteps to predict\n",
    "            freq_type: Frequency type (0, 1, or 2)\n",
    "        \"\"\"\n",
    "    if freq_type not in [0, 1, 2]:\n",
    "      raise ValueError(\"freq_type must be 0, 1, or 2\")\n",
    "\n",
    "    self.series = series\n",
    "    self.context_length = context_length\n",
    "    self.horizon_length = horizon_length\n",
    "    self.freq_type = freq_type\n",
    "    self._prepare_samples()\n",
    "\n",
    "  def _prepare_samples(self) -> None:\n",
    "    \"\"\"Prepare sliding window samples from the time series.\"\"\"\n",
    "    self.samples = []\n",
    "    total_length = self.context_length + self.horizon_length\n",
    "\n",
    "    for start_idx in range(0, len(self.series) - total_length + 1):\n",
    "      end_idx = start_idx + self.context_length\n",
    "      x_context = self.series[start_idx:end_idx]\n",
    "      x_future = self.series[end_idx:end_idx + self.horizon_length]\n",
    "      self.samples.append((x_context, x_future))\n",
    "\n",
    "  def __len__(self) -> int:\n",
    "    return len(self.samples)\n",
    "\n",
    "  def __getitem__(\n",
    "      self, index: int\n",
    "  ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    x_context, x_future = self.samples[index]\n",
    "\n",
    "    x_context = torch.tensor(x_context, dtype=torch.float32)\n",
    "    x_future = torch.tensor(x_future, dtype=torch.float32)\n",
    "\n",
    "    input_padding = torch.zeros_like(x_context)\n",
    "    freq = torch.tensor([self.freq_type], dtype=torch.long)\n",
    "\n",
    "    return x_context, input_padding, freq, x_future\n",
    "\n",
    "def prepare_datasets(series: np.ndarray,\n",
    "                     context_length: int,\n",
    "                     horizon_length: int,\n",
    "                     freq_type: int = 0,\n",
    "                     train_split: float = 0.8) -> Tuple[Dataset, Dataset]:\n",
    "  \"\"\"\n",
    "    Prepare training and validation datasets from time series data.\n",
    "\n",
    "    Args:\n",
    "        series: Input time series data\n",
    "        context_length: Number of past timesteps to use\n",
    "        horizon_length: Number of future timesteps to predict\n",
    "        freq_type: Frequency type (0, 1, or 2)\n",
    "        train_split: Fraction of data to use for training\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_dataset, val_dataset)\n",
    "    \"\"\"\n",
    "  train_size = int(len(series) * train_split)\n",
    "  train_data = series[:train_size]\n",
    "  val_data = series[train_size:]\n",
    "\n",
    "  # Create datasets with specified frequency type\n",
    "  train_dataset = TimeSeriesDataset(train_data,\n",
    "                                    context_length=context_length,\n",
    "                                    horizon_length=horizon_length,\n",
    "                                    freq_type=freq_type)\n",
    "\n",
    "  val_dataset = TimeSeriesDataset(val_data,\n",
    "                                  context_length=context_length,\n",
    "                                  horizon_length=horizon_length,\n",
    "                                  freq_type=freq_type)\n",
    "\n",
    "  return train_dataset, val_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a94d8650-6ceb-4306-8c4a-3e78b3686498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fa5f75a16244cd84e5e66993ee8187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             日期     开盘     收盘     最高     最低      成交量          成交额    振幅   涨跌幅  \\\n",
      "0    2022-02-18  0.997  0.989  1.004  0.988  2917198  292174176.0  1.57 -2.94   \n",
      "1    2022-02-21  0.965  0.948  0.973  0.944   846233   80811395.0  2.93 -4.15   \n",
      "2    2022-02-22  0.930  0.922  0.940  0.913  1457760  134019602.0  2.85 -2.74   \n",
      "3    2022-02-23  0.928  0.940  0.944  0.922  1404163  131535030.0  2.39  1.95   \n",
      "4    2022-02-24  0.917  0.906  0.931  0.886  1353017  122475991.0  4.79 -3.62   \n",
      "..          ...    ...    ...    ...    ...      ...          ...   ...   ...   \n",
      "827  2025-07-17  1.110  1.116  1.121  1.108  4662467  519992175.0  1.17  0.09   \n",
      "828  2025-07-18  1.132  1.134  1.139  1.128  4006023  454250379.0  0.99  1.61   \n",
      "829  2025-07-21  1.151  1.144  1.151  1.134  4434565  506451738.0  1.50  0.88   \n",
      "830  2025-07-22  1.141  1.130  1.145  1.127  3614534  409798410.0  1.57 -1.22   \n",
      "831  2025-07-23  1.138  1.160  1.165  1.133  6481090  747140338.0  2.83  2.65   \n",
      "\n",
      "       涨跌额    换手率  \n",
      "0   -0.030   4.63  \n",
      "1   -0.041   1.34  \n",
      "2   -0.026   2.31  \n",
      "3    0.018   2.23  \n",
      "4   -0.034   2.15  \n",
      "..     ...    ...  \n",
      "827  0.001   7.40  \n",
      "828  0.018   6.36  \n",
      "829  0.010   7.04  \n",
      "830 -0.014   5.74  \n",
      "831  0.030  10.29  \n",
      "\n",
      "[832 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import akshare as ak\n",
    "\n",
    "fund_etf_hist_em_df = ak.fund_etf_hist_em(symbol=\"513770\", period=\"daily\", start_date=\"20220218\", end_date=\"20250723\", adjust=\"\")\n",
    "print(fund_etf_hist_em_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec64806f-8b76-4e82-8414-01b74c6c1e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.989 0.948 0.922 0.94  0.906 0.907 0.896 0.918 0.897 0.874 0.84  0.811\n",
      " 0.781 0.773 0.776 0.75  0.69  0.626 0.689 0.758 0.797 0.781 0.795 0.842\n",
      " 0.818 0.772 0.791 0.817 0.827 0.806 0.798 0.83  0.802 0.79  0.747 0.769\n",
      " 0.765 0.777 0.77  0.765 0.747 0.748 0.719 0.724 0.692 0.716 0.731 0.737\n",
      " 0.806 0.784 0.75  0.742 0.734 0.759 0.748 0.784 0.786 0.825 0.814 0.793\n",
      " 0.814 0.79  0.756 0.765 0.762 0.781 0.803 0.83  0.829 0.826 0.849 0.866\n",
      " 0.904 0.89  0.914 0.885 0.89  0.9   0.874 0.887 0.891 0.91  0.885 0.896\n",
      " 0.926 0.954 0.967 0.936 0.924 0.925 0.934 0.932 0.907 0.911 0.915 0.877\n",
      " 0.869 0.876 0.872 0.85  0.876 0.87  0.887 0.879 0.88  0.865 0.876 0.863\n",
      " 0.866 0.82  0.819 0.796 0.803 0.827 0.834 0.822 0.818 0.789 0.812 0.82\n",
      " 0.83  0.8   0.804 0.798 0.807 0.805 0.801 0.777 0.808 0.812 0.817 0.803\n",
      " 0.823 0.803 0.798 0.789 0.787 0.778 0.767 0.785 0.781 0.764 0.765 0.753\n",
      " 0.734 0.743 0.73  0.715 0.708 0.72  0.726 0.713 0.69  0.672 0.664 0.653\n",
      " 0.66  0.633 0.647 0.642 0.67  0.655 0.641 0.644 0.587 0.596 0.617 0.621\n",
      " 0.587 0.603 0.656 0.674 0.659 0.705 0.725 0.718 0.698 0.677 0.726 0.744\n",
      " 0.786 0.785 0.782 0.788 0.771 0.735 0.746 0.735 0.726 0.719 0.764 0.777\n",
      " 0.812 0.814 0.883 0.863 0.864 0.892 0.912 0.885 0.902 0.899 0.87  0.876\n",
      " 0.87  0.836 0.841 0.885 0.875 0.867 0.886 0.886 0.875 0.875 0.886 0.928\n",
      " 0.935 0.915 0.936 0.93  0.925 0.893 0.914 0.89  0.89  0.897 0.891 0.916\n",
      " 0.925 0.902 0.939 0.942 0.936 0.896 0.901 0.88  0.91  0.878 0.877 0.871\n",
      " 0.858 0.874 0.855 0.866 0.84  0.823 0.827 0.822 0.81  0.81  0.851 0.844\n",
      " 0.861 0.851 0.83  0.811 0.807 0.772 0.79  0.768 0.778 0.769 0.799 0.773\n",
      " 0.792 0.805 0.835 0.848 0.841 0.836 0.852 0.846 0.848 0.848 0.846 0.833\n",
      " 0.85  0.851 0.839 0.824 0.814 0.819 0.834 0.822 0.814 0.811 0.784 0.776\n",
      " 0.762 0.782 0.774 0.787 0.765 0.78  0.776 0.756 0.757 0.747 0.754 0.772\n",
      " 0.769 0.766 0.761 0.754 0.772 0.764 0.75  0.738 0.735 0.724 0.736 0.715\n",
      " 0.732 0.768 0.77  0.76  0.777 0.769 0.782 0.782 0.803 0.794 0.818 0.829\n",
      " 0.806 0.795 0.769 0.76  0.779 0.78  0.769 0.761 0.782 0.783 0.774 0.76\n",
      " 0.752 0.756 0.761 0.77  0.809 0.803 0.79  0.783 0.787 0.776 0.781 0.769\n",
      " 0.807 0.809 0.818 0.851 0.868 0.855 0.831 0.848 0.852 0.851 0.835 0.836\n",
      " 0.837 0.82  0.812 0.817 0.805 0.819 0.789 0.77  0.783 0.785 0.819 0.804\n",
      " 0.814 0.826 0.812 0.799 0.805 0.815 0.8   0.796 0.788 0.781 0.785 0.787\n",
      " 0.779 0.783 0.785 0.774 0.769 0.761 0.744 0.766 0.753 0.745 0.747 0.735\n",
      " 0.737 0.75  0.767 0.777 0.761 0.747 0.753 0.74  0.732 0.724 0.711 0.709\n",
      " 0.714 0.713 0.726 0.734 0.728 0.725 0.729 0.756 0.787 0.783 0.787 0.787\n",
      " 0.767 0.775 0.778 0.795 0.789 0.768 0.781 0.775 0.764 0.774 0.762 0.763\n",
      " 0.752 0.729 0.728 0.724 0.708 0.688 0.704 0.697 0.7   0.696 0.71  0.69\n",
      " 0.694 0.703 0.693 0.685 0.684 0.683 0.644 0.651 0.647 0.659 0.675 0.67\n",
      " 0.667 0.661 0.657 0.648 0.63  0.623 0.616 0.64  0.63  0.628 0.617 0.578\n",
      " 0.585 0.567 0.546 0.565 0.579 0.591 0.569 0.565 0.547 0.526 0.539 0.536\n",
      " 0.538 0.57  0.563 0.564 0.581 0.581 0.604 0.605 0.611 0.607 0.605 0.596\n",
      " 0.603 0.611 0.613 0.594 0.601 0.59  0.603 0.622 0.657 0.66  0.646 0.639\n",
      " 0.662 0.648 0.653 0.665 0.648 0.64  0.648 0.636 0.651 0.662 0.68  0.669\n",
      " 0.656 0.65  0.659 0.665 0.668 0.663 0.655 0.634 0.635 0.636 0.619 0.64\n",
      " 0.668 0.697 0.69  0.723 0.721 0.716 0.775 0.756 0.746 0.761 0.761 0.78\n",
      " 0.789 0.792 0.792 0.797 0.803 0.773 0.776 0.767 0.742 0.756 0.75  0.734\n",
      " 0.727 0.723 0.731 0.741 0.736 0.738 0.727 0.727 0.721 0.729 0.732 0.728\n",
      " 0.726 0.751 0.739 0.727 0.711 0.713 0.721 0.698 0.692 0.693 0.686 0.705\n",
      " 0.704 0.698 0.685 0.695 0.694 0.705 0.728 0.709 0.7   0.704 0.702 0.689\n",
      " 0.702 0.685 0.668 0.653 0.658 0.668 0.653 0.675 0.671 0.648 0.638 0.646\n",
      " 0.652 0.652 0.656 0.653 0.656 0.644 0.643 0.656 0.665 0.655 0.646 0.656\n",
      " 0.655 0.663 0.657 0.648 0.661 0.68  0.664 0.668 0.661 0.666 0.66  0.659\n",
      " 0.662 0.659 0.666 0.664 0.675 0.695 0.694 0.692 0.721 0.726 0.778 0.828\n",
      " 0.905 0.923 0.868 0.883 0.854 0.863 0.82  0.822 0.818 0.856 0.844 0.851\n",
      " 0.867 0.847 0.848 0.86  0.862 0.849 0.851 0.85  0.858 0.882 0.877 0.909\n",
      " 0.905 0.897 0.869 0.864 0.852 0.845 0.844 0.848 0.866 0.859 0.833 0.825\n",
      " 0.826 0.847 0.838 0.839 0.851 0.855 0.853 0.848 0.868 0.868 0.885 0.875\n",
      " 0.899 0.873 0.856 0.852 0.862 0.862 0.862 0.856 0.867 0.865 0.865 0.867\n",
      " 0.864 0.849 0.838 0.843 0.841 0.819 0.809 0.814 0.796 0.789 0.817 0.812\n",
      " 0.822 0.827 0.844 0.85  0.828 0.823 0.85  0.868 0.921 0.935 0.959 0.992\n",
      " 0.976 0.997 1.02  1.067 1.083 1.111 1.115 1.086 1.144 1.149 1.106 1.152\n",
      " 1.129 1.064 1.071 1.084 1.119 1.188 1.177 1.151 1.145 1.132 1.107 1.148\n",
      " 1.15  1.179 1.176 1.135 1.103 1.107 1.077 1.083 1.087 1.072 1.05  1.058\n",
      " 1.053 1.04  0.936 0.9   0.927 0.964 0.971 0.977 0.975 0.941 0.949 0.944\n",
      " 0.954 0.963 1.002 0.983 0.993 0.994 0.987 1.013 1.052 1.041 1.04  1.031\n",
      " 1.044 1.036 1.055 1.043 1.039 1.035 1.047 1.052 1.032 1.031 1.019 1.024\n",
      " 1.021 1.041 1.016 1.022 1.027 1.048 1.044 1.07  1.063 1.081 1.07  1.046\n",
      " 1.072 1.073 1.059 1.031 1.031 1.047 1.07  1.079 1.067 1.081 1.081 1.081\n",
      " 1.065 1.049 1.044 1.043 1.068 1.057 1.059 1.075 1.07  1.107 1.115 1.116\n",
      " 1.134 1.144 1.13  1.16 ]\n",
      "Created datasets:\n",
      "- Training samples: 359\n",
      "- Validation samples: 27\n",
      "- Using frequency type: 1\n",
      "<__main__.TimeSeriesDataset object at 0x0000014CFC0CFAA0> <__main__.TimeSeriesDataset object at 0x0000014CFC48FA40>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 获取并且预处理数据\n",
    "# 通过fund_etf_hist_em_df接口获取国内公募基金股票数据，替换国外的\n",
    "# 数据不够，修改get_data函数的训练数据长度，可以修改为32、64、96、128；验证数据的长度为模型配置参数，不可修改\n",
    "\n",
    "import akshare as ak\n",
    "\n",
    "def get_data(context_len: int,\n",
    "             horizon_len: int,\n",
    "             freq_type: int = 0) -> Tuple[Dataset, Dataset]:\n",
    "  fund_etf_hist_em_df = ak.fund_etf_hist_em(symbol=\"513770\", period=\"daily\", start_date=\"20220218\", end_date=\"20250723\", adjust=\"\")\n",
    "  time_series = fund_etf_hist_em_df[\"收盘\"].values\n",
    "\n",
    "  train_dataset, val_dataset = prepare_datasets(\n",
    "      series=time_series,\n",
    "      context_length=context_len,\n",
    "      horizon_length=horizon_len,\n",
    "      freq_type=freq_type,\n",
    "      train_split=0.7,\n",
    "  )\n",
    "  print(time_series)\n",
    "  print(f\"Created datasets:\")\n",
    "  print(f\"- Training samples: {len(train_dataset)}\")\n",
    "  print(f\"- Validation samples: {len(val_dataset)}\")\n",
    "  print(f\"- Using frequency type: {freq_type}\")\n",
    "  return train_dataset, val_dataset\n",
    "\n",
    "train_dataset, val_dataset = get_data(96,\n",
    "                                    tfm_config.horizon_len,\n",
    "                                    freq_type=config.freq_type)\n",
    "\n",
    "print(train_dataset, val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8926af6e-6c1c-405e-b271-f4788dc19872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting finetuning...\n",
      "\n",
      "Finetuning completed!\n",
      "Training history: 5 epochs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 微调模型\n",
    "\n",
    "finetuner = TimesFMFinetuner(model, config)\n",
    "\n",
    "print(\"\\nStarting finetuning...\")\n",
    "results = finetuner.finetune(train_dataset=train_dataset,\n",
    "                           val_dataset=val_dataset)\n",
    "\n",
    "print(\"\\nFinetuning completed!\")\n",
    "print(f\"Training history: {len(results['history']['train_loss'])} epochs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "396b4800-9471-4d56-aa51-7eafac48a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 训练数据、验证数据、预测数据的图，可看出模型微调的好坏\n",
    "\n",
    "def plot_predictions(\n",
    "    model: TimesFm,\n",
    "    val_dataset: Dataset,\n",
    "    save_path: Optional[str] = \"predictions.png\",\n",
    ") -> None:\n",
    "  \"\"\"\n",
    "    Plot model predictions against ground truth for a batch of validation data.\n",
    "\n",
    "    Args:\n",
    "      model: Trained TimesFM model\n",
    "      val_dataset: Validation dataset\n",
    "      save_path: Path to save the plot\n",
    "    \"\"\"\n",
    "  import matplotlib.pyplot as plt\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  x_context, x_padding, freq, x_future = val_dataset[0]\n",
    "  x_context = x_context.unsqueeze(0)  # Add batch dimension\n",
    "  x_padding = x_padding.unsqueeze(0)\n",
    "  freq = freq.unsqueeze(0)\n",
    "  x_future = x_future.unsqueeze(0)\n",
    "\n",
    "  device = next(model.parameters()).device\n",
    "  x_context = x_context.to(device)\n",
    "  x_padding = x_padding.to(device)\n",
    "  freq = freq.to(device)\n",
    "  x_future = x_future.to(device)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    predictions = model(x_context, x_padding.float(), freq)\n",
    "    predictions_mean = predictions[..., 0]  # [B, N, horizon_len]\n",
    "    last_patch_pred = predictions_mean[:, -1, :]  # [B, horizon_len]\n",
    "\n",
    "  context_vals = x_context[0].cpu().numpy()\n",
    "  future_vals = x_future[0].cpu().numpy()\n",
    "  pred_vals = last_patch_pred[0].cpu().numpy()\n",
    "\n",
    "  context_len = len(context_vals)\n",
    "  horizon_len = len(future_vals)\n",
    "\n",
    "  plt.figure(figsize=(12, 6))\n",
    "\n",
    "  plt.plot(range(context_len),\n",
    "           context_vals,\n",
    "           label=\"Historical Data\",\n",
    "           color=\"blue\",\n",
    "           linewidth=2)\n",
    "\n",
    "  plt.plot(\n",
    "      range(context_len, context_len + horizon_len),\n",
    "      future_vals,\n",
    "      label=\"Ground Truth\",\n",
    "      color=\"green\",\n",
    "      linestyle=\"--\",\n",
    "      linewidth=2,\n",
    "  )\n",
    "\n",
    "  plt.plot(range(context_len, context_len + horizon_len),\n",
    "           pred_vals,\n",
    "           label=\"Prediction\",\n",
    "           color=\"red\",\n",
    "           linewidth=2)\n",
    "\n",
    "  plt.xlabel(\"Time Step\")\n",
    "  plt.ylabel(\"Value\")\n",
    "  plt.title(\"TimesFM Predictions vs Ground Truth\")\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "  if save_path:\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Plot saved to {save_path}\")\n",
    "\n",
    "  plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0e449d-c019-4c2a-bda1-92795dca9d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to timesfm_predictions.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 绘图\n",
    "\n",
    "plot_predictions(\n",
    "      model=model,\n",
    "      val_dataset=val_dataset,\n",
    "      save_path=\"timesfm_predictions.png\",\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62338e0-d7c1-4bf4-9754-aebcacaa0df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
