langextract用于从非结构化数据中提取结构化数据，直白点，就是从非结构化数据中找出内容填写文件的问题。

一个lx.data.Extraction是一个对象的内容，比如一个人的信息，当然有必要，也可以把一个人的信息的几部分，分为不同的lx.data.Extraction。extraction_class相当于标签、extraction_text写入提取的原文部分、attributes属性写入提取的结构化数据，这三者组合教会模型，怎么提取。

pip安装就可以。

难点在于，这个谷歌开源的，对自己模型的支持更好，更方便配置，所以，第一个难点在于模型配置，看示例文档；第二个难点在于，库文件里面数据的传递都限制了utf-8格式，所以库文件不存在问题，官方示例使用代码对html读取后再加载没规定，造成生成的可视化网页乱码，我的示例文档对这部分代码做了修改，已解决。
